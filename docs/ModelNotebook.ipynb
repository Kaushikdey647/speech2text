{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# speech2text\n",
    "- Its a simple notebook to convert speech to text.\n",
    "- We will be using wave2vec herre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get the libraries\n",
    "- Make sure you have them installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile\n",
    "from ipywebrtc import AudioRecorder\n",
    "from IPython.display import Audio\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "/home/kaydee647/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:754: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load the audio data and Framerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling rate: 44100  Hz\n"
     ]
    }
   ],
   "source": [
    "audio_path = 'audio_5.wav'\n",
    "[framerate, sound_dat] = wavfile.read(audio_path)\n",
    "# time = np.arange( 0, len(sound_dat) )/framerate\n",
    "print('Sampling rate:', framerate, ' Hz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Convert the audio to spectrogram\n",
    "We used the sampling rate of 16000 as word2vec accepts this sampling range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -1.3119541e-04\n",
      " -4.4363615e-06  0.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "input_audio, _ = librosa.load(audio_path, sr=16000)\n",
    "print(input_audio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Convert the spectrogram to word2vec\n",
    "Tokenize the spectogram and convert it to word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 13:33:16.853410: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-07-04 13:33:16.856300: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-04 13:33:16.856316: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_values': tensor([[-9.4060e-05, -9.4060e-05, -9.4060e-05,  ..., -1.0590e-03,\n",
      "         -1.2669e-04, -9.4060e-05]])}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "token = tokenizer(input_audio, return_tensors='pt')\n",
    "print(token)\n",
    "input_values = token['input_values']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Get the prediction\n",
    "- The prediction is taken in form of logits\n",
    "- In Math, Logit is a function that maps probabilities ([0, 1]) to R ((-inf, inf))\n",
    "- If you know softmax, it is kindof the inverse of that function(not exactly)\n",
    "- L = ln(P/(1-P)) where P is the probability of the class and 1-P is the probability of the other class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 13.7284, -25.7757, -25.5137,  ...,  -6.2650,  -6.9997,  -7.8211],\n",
      "         [ 13.7605, -25.7770, -25.5154,  ...,  -6.2344,  -6.9767,  -7.8130],\n",
      "         [ 13.8425, -25.7324, -25.4717,  ...,  -6.2120,  -7.0354,  -7.7811],\n",
      "         ...,\n",
      "         [ 13.5866, -25.7665, -25.5632,  ...,  -6.2777,  -6.9433,  -7.5408],\n",
      "         [ 13.7977, -26.1069, -25.8621,  ...,  -6.6500,  -7.7482,  -7.5035],\n",
      "         [ 13.8326, -26.0904, -25.8520,  ...,  -6.6140,  -7.6000,  -7.5594]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logits = model(input_values).logits\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. But dude, what is argmax?\n",
    "- argmax is the index of the maximum value in the array\n",
    "- In this case, every index of the logit has an array of probabilities (in logits ofc)\n",
    "- So, the index of the maximum value in the logit is the index of the class that is highly probable\n",
    "- We take that for every token and say that it is the predicted indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10,\n",
      "         10,  0,  0, 27, 17,  0,  0,  4,  0,  6,  0,  5, 15,  0,  0,  0, 15, 10,\n",
      "          9,  0, 21,  4,  4, 22,  0,  8, 16,  0,  4,  4,  0, 24,  0, 13,  0,  0,\n",
      "          0,  8,  0,  0,  0,  0,  0,  0,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  6, 11,  0, 10,  0, 12, 12,  0,  4,  0,  0,  0,\n",
      "          0, 23,  0, 13,  0,  0,  8,  0,  0, 14,  0, 16,  0, 19,  0,  0,  6,  0,\n",
      "          0,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10,  6,  0,  4,  4, 18,\n",
      "          0,  0, 10, 15,  0,  0,  0, 15,  0,  4,  4,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0, 19, 11, 11,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          7,  0,  9,  9,  9,  0, 21,  5,  5,  0,  4,  4, 22, 22,  0,  8, 16,  0,\n",
      "          0,  4,  4,  4,  0,  0,  0,  0, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0, 10,  0,  0, 20,  5,  0,  4,  4,  4,  4,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "predicted_indices = torch.argmax(logits, dim=-1)\n",
    "print(predicted_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Did you know that we could use the argmax to get the predicted text?\n",
    "- tokenizer of word2vec2 has a function called batch_decode that takes the predicted indices and returns the predicted text\n",
    "- In this case the predicted indices has only one array, which indicates there is only one text in the prediction?\n",
    "- This is because we took only one that has the highest probability.... remember??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'M TELLING YOU BRO THIS PRODUCT IT WILL CHANGE YOU LIFE\n"
     ]
    }
   ],
   "source": [
    "transcription = tokenizer.batch_decode(predicted_indices)[0] #Since there is only one\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. OK WE SAVE THE MODELS NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./saved_model/tokenizer/tokenizer_config.json',\n",
       " './saved_model/tokenizer/special_tokens_map.json',\n",
       " './saved_model/tokenizer/vocab.json',\n",
       " './saved_model/tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./saved_model/model')\n",
    "tokenizer.save_pretrained('./saved_model/tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaydee647/.local/lib/python3.8/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:754: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"saved_model/tokenizer\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"saved_model/model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
